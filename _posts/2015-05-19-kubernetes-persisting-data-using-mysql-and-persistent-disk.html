---
layout: post
title: Kubernetes persisting data using MySql and Persistent Disk
date: 2015-05-19 12:28:29.000000000 +01:00
type: post
published: true
status: publish
categories: []
tags:
- docker
- example
- kubernetes
- mysql
- persistent disk
- tutorial
meta:
  _publicize_pending: '1'
  _rest_api_published: '1'
  _rest_api_client_id: "-1"
author:
  login: stevenwilliamalexander
  email: steven.william.alexander@googlemail.com
  display_name: stevenwilliamalexander
  first_name: ''
  last_name: ''
---
<p>This is a description of the steps to deploy a microservice on a <a href="http://kubernetes.io/">kubernetes</a> cluster with persistent storage via a database pod.</p>
<p>Source <a href="https://github.com/stevenalexander/docker-authentication-authorisation">here</a>.</p>
<p>I'm using an existing microservice I created for storing session details, described <a href="https://github.com/stevenalexander/docker-authentication-authorisation">here</a>.</p>
<p>Based on the Kubernetes <a href="https://cloud.google.com/container-engine/docs/tutorials/persistent-disk">Using Persistent Disks</a> tutorial.</p>
<p>Requires:</p>
<ul>
<li><a href="https://cloud.google.com/">Google Cloud</a> account (free trial needs payment details)</li>
<li><a href="https://cloud.google.com/container-engine/docs/before-you-begin#install_the_gcloud_command_line_interface">gcloud</a> tools (I recommend you do one of the <a href="https://cloud.google.com/container-engine/docs/tutorials/hello-wordpress">container engine tutorials</a> first)</li>
<li><a href="https://www.docker.com/">Docker</a></li>
<li>JDK (to compile java file locally)</li>
<li><a href="https://gradle.org/">Gradle</a> (for build automation)</li>
</ul>
<h2><a id="user-content-setup" class="anchor" href="https://github.com/stevenalexander/docker-authentication-authorisation/blob/master/kubernetes-persistent-disks.md#setup"></a>Setup</h2>
<ol>
<li>Build microservices and copy jar/config into volumes</li>
</ol>
<pre><code>gradle buildJar

</code></pre>
<p>You can test DB access locally by spinning up a <a href="https://registry.hub.docker.com/_/mysql/">MySql</a> container, setting the database environment variable to create the <code>session</code> DB, then starting the microservice container linked to the MySql container. This mirrors how it will connect to the Kubernetes data Pod when it is run as a Service (connecting by <a href="https://cloud.google.com/container-engine/docs/tutorials/persistent-disk/#mysql_service">Service host name</a>).</p>
<pre><code># MySql container with environment variable to create DB and link to session microservice container
docker run --name session-mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=root -e MYSQL_DATABASE=session -d mysql:latest
docker run -it --link session-mysql:session-mysql --rm -p 8084:8084 stevena/persistent-disks-session:latest
</code></pre>
<ol>
<li>Login to gcloud and set project/zone</li>
</ol>
<pre><code>gcloud auth login
gcloud config set project PROJECTID
gcloud config set compute/zone europe-west1-b
</code></pre>
<ol>
<li>Build the container images and publish to <a href="https://cloud.google.com/tools/container-registry/">Google Container Registry</a></li>
</ol>
<p>These container images are largely the same as the definitions from the <a href="https://github.com/stevenalexander/docker-authentication-authorisation/blob/master/dev-docker-compose.yml">Development Docker Compose file</a> with the exception that the jars/config files are copied into the images to avoid needing mounted volumes.</p>
<pre><code># Build
docker build -t stevena/persistent-disks-session:latest -f kubernetes/persistent-disks/Dockerfile-session .

# Tag
docker tag stevena/persistent-disks-session gcr.io/PROJECTID/persistent-disks-session

# Publish
gcloud preview docker push gcr.io/PROJECTID/persistent-disks-session
</code></pre>
<ol>
<li>Create the Google Cloud persistent disk for MySql</li>
</ol>
<pre><code># size is 200GB for performance recommendations https://developers.google.com/compute/docs/disks/persistent-disks#pdperformance
gcloud compute disks create --size 200GB persistent-disks-session-mysql-disk
</code></pre>
<ol>
<li>Create the Cluster, Pod and allow external web access</li>
</ol>
<pre><code># Create cluster
gcloud alpha container clusters create session-persist --num-nodes 2 --machine-type g1-small
gcloud config set container/cluster session-persist

# MySql pod and Service
gcloud alpha container kubectl create -f kubernetes/persistent-disks/mysql-pod.yaml
gcloud alpha container kubectl create -f kubernetes/persistent-disks/mysql-service.yaml

# Session pod
gcloud alpha container kubectl create -f kubernetes/persistent-disks/session-pod.yaml
# see pod and get external IP from HOST column `gcloud alpha container kubectl get pods`

# Allow external web access
gcloud compute firewall-rules create k8s-session-persist-node-80 --allow tcp:80 --target-tags k8s-session-persist-node

# cURL service
curl 'http://PODIP/api/sessions' --data-binary '1234'
curl 'http://PODIP/api/sessions/ACCESSTOKENFROMABOVE'

# DEBUG
# check pod logs with `gcloud alpha container kubectl log single-session-persist session`,
# ssh onto node with `gcloud compute ssh k8s-session-persist-node-1`, access container `sudo docker exec -it CONTAINERID bash`

# Delete MySql pod and restart to test persisted data
gcloud alpha container kubectl delete -f kubernetes/persistent-disks/mysql-pod.yaml
# curl service and see error as DB is down
gcloud alpha container kubectl create -f kubernetes/persistent-disks/mysql-pod.yaml
# curl service with previously created token and see it has restarted with data from persistent disk
</code></pre>
<h2><a id="user-content-clean-up" class="anchor" href="https://github.com/stevenalexander/docker-authentication-authorisation/blob/master/kubernetes-persistent-disks.md#clean-up"></a>Clean up</h2>
<pre><code>gcloud alpha container clusters delete session-persist
gcloud compute firewall-rules delete k8s-session-persist-node-80
gcloud compute disks delete persistent-disks-session-mysql-disk
</code></pre>
<h2><a id="user-content-conclusion" class="anchor" href="https://github.com/stevenalexander/docker-authentication-authorisation/blob/master/kubernetes-persistent-disks.md#conclusion"></a>Conclusion</h2>
<p>I like the idea of easily creating database containers per microservice, saving all persisted data on a store that can be easily backed up and controlled. Using this approach avoids the performance trap of a monolithic database saving all your data from the entire solution. The MySql pod started up extremely fast and there were no problems when I deleted then restarted the pod.</p>
<p>Still a lot of things would need to be considered, replication, user control (I used root access for simplicity) and data migration/updates. Most likely you would need to make custom Dockerfile database containers per store, which includes logic for how to setup/control the container. Think I would need to sit down with a DBA to discuss how you could manange and maintain production databases when using this approach.</p>
